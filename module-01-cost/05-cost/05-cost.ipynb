{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMPS 2200\n",
    "# Introduction to Algorithms\n",
    "\n",
    "## Cost models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today's agenda:\n",
    "\n",
    "- Three different ways to model computational cost\n",
    "  + Random Access Machine\n",
    "  + Parallel Random Access Machine\n",
    "  + Language Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall first lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def linear_search(mylist, key):        #   cost         number of times run\n",
    "    for i,v in enumerate(mylist):      #   c1               n\n",
    "        if v == key:                   #   c2               n\n",
    "            return i                   #   c3               0\n",
    "    return -1                          #   c4               1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\hbox{Cost(linear-search, } n) = c_1n + c_2n + c_4 = O(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## machine-based cost model\n",
    "\n",
    "- define the cost of each instruction  \n",
    "- runtime is sum of costs of each instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Access Machine model\n",
    "\n",
    "- \"Simple\" operations (+, *, =, if) take exactly one time step\n",
    "  - no matter the size of operands\n",
    "- loops consist of many single-step operations\n",
    "- **memory access takes one step**\n",
    "  - unbounded memory\n",
    "  - each cell holds integers of unbounded size\n",
    "- assumes sequential execution\n",
    "- one input tape, one output tape\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "To compute the run time of an algorithm, we:\n",
    "1. compute the number of steps\n",
    "2. determine the number of steps per second our machine can perform\n",
    "3. time = steps / steps per second\n",
    "\n",
    "<br><br>\n",
    "\n",
    "All models make incorrect assumptions. What are some that the RAM model makes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- multiplication does not take the same time as addition\n",
    "- cache is faster than RAM\n",
    "\n",
    "<br>\n",
    "\n",
    "Not terrible assumptions since we are interested in asymptotic analysis.\n",
    "\n",
    "E.g., if cache lookup is half the time of RAM lookup, then we're \"only\" off by a factor of 2.  \n",
    "E.g. $2n \\in O(n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PRAM: Parallel Random Access Machine\n",
    "\n",
    "- The RAM model extended to have \n",
    "  - multiple processors $P_0, P_1, P_2 \\ldots$\n",
    "  - unbounded, **shared** memory cells $M[0], M[1], M[2] \\ldots$\n",
    "  - any processor $P_i$ can access any memory cell $M[j]$ in one time step\n",
    "  \n",
    "![pram.jpg](figures/pram.jpg)  \n",
    "[source](https://www.tutorialspoint.com/parallel_algorithm/parallel_random_access_machines.htm)\n",
    "\n",
    "<br>\n",
    "Assumes some control mechanisms to deal with race conditions/synchronization.\n",
    "\n",
    "<br><br>\n",
    "To compute the runtime:\n",
    "- compute time for the slowest processor\n",
    "\n",
    "\n",
    "<br><br>\n",
    "Two drawbacks of this model:\n",
    "\n",
    "1. Mapping data to each processor can be tricky\n",
    "2. Nested parallelism is hard to specify in this model (e.g., recursive fork-join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithmic Cost  Models\n",
    "\n",
    "- Define a language to specify algorithms\n",
    "- Assign a cost to each expression\n",
    "- Cost of algorithm is sum of costs for each expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SPARC Work-Span model\n",
    "\n",
    "- Language based model for SPARC\n",
    "\n",
    "Recall our definitions of **work** and **span**\n",
    "\n",
    "> **work**: total number of primitive operations performed by an algorithm\n",
    "\n",
    "> **span**: longest sequence of dependencies in computation\n",
    "- time to run with an infinite number of processors\n",
    "- measure of how \"parallelized\" an algorithm is \n",
    "- also called: *critical path length* or *computational depth*\n",
    "\n",
    "<br>\n",
    "\n",
    "**intuition**:  \n",
    "**work**: total energy consumed by a computation  \n",
    "**span**: minimum possible time that the computation requires\n",
    "\n",
    "<br>\n",
    "        \n",
    "**work**: $T_1$ = time using one processor  \n",
    "**span**: $T_\\infty$ = time using $\\infty$ processors\n",
    "\n",
    "For a given SPARC expression $e$, we will analyze the work $W(e)$ and span $S(e)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Composition\n",
    "\n",
    "<img src=\"figures/composition.png\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "-   $(e_1, e_2)$: Sequential Composition\n",
    "\n",
    "    -   Add work and span\n",
    "\n",
    "-   $(e_1 || e_2)$: Parallel Composition\n",
    "\n",
    "    -   Add work but **take the maximum span**\n",
    "    \n",
    "    \n",
    "\n",
    "### Rules of composition\n",
    "\n",
    "\n",
    "|        $\\mathbf{e}$   |        $\\mathbf{W(e)}$         |        $\\mathbf{S(e)}$         |\n",
    "| --------------------- | ------------------------------ | ------------------------------ |\n",
    "|       $v$             |              $1$               |             $1$                |\n",
    "|$\\mathtt{lambda}\\:p\\:.\\:e$|              $1$            |             $1$                |\n",
    "|     $(e_1, e_2)$      |     $1 + W(e_1) + W(e_2)$      |     $1 + S(e_1) + S(e_2)$      |\n",
    "|    $(e_1 || e_2)$     |     $1 + W(e_1) + W(e_2)$      |   $1 + \\max(S(e_1), S(e_2))$   |\n",
    "| $(e_1 e_2)$           |  $W(e_1) + W(e_2) + W([\\hbox{Eval}(e_2)/x]e_3) + 1$ | $S(e_1) + S(e_2) + S([\\hbox{Eval}(e_2)/x]e_3) + 1$ \n",
    "|   `let val` $x=e_1$ `in` $e_2$ `end`  |  $1 + W(e_1) + W([\\hbox{Eval}(e_1)/x]e_2)$       |     $1 + S(e_1) +     S([\\hbox{Eval}(e_1)/x]e_2)$  |\n",
    "| $\\{f(x)\\mid x\\in A\\}$ |   $1+\\sum_{x\\in A} W(f(x))$    |   $1+\\max_{x\\in A} S(f(x))$    |\n",
    "\n",
    "\n",
    "## parallel composition: $e_1 || e_2$\n",
    "\n",
    "$W(e_1 || e_2) = 1 + W(e_1) + W(e_2)$  \n",
    "$S(e_1 || e_2) = 1 + \\max(S(e_1), S(e_2))$  \n",
    "\n",
    "What are we assuming here?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A *pure* functional language, we can run two functions in parallel if there is no explicit sequencing.\n",
    "\n",
    "- no side effects\n",
    "- data persistence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## function application: $e_1 e_2$\n",
    "\n",
    "$W(e_1 e_2) = W(e_1) + W(e_2) + W([\\hbox{Eval}(e_2)/x]e_3) + 1$  \n",
    "\n",
    "\n",
    "\n",
    "- $\\hbox{Eval}(e)$ evaluates $e$ and returns resulting value\n",
    "- $[v/x]e$: replace all free (unbound) occurrences of $x$ in $e$ with value $v$ \n",
    "  - e.g., $[10/x](x^2+10) \\rightarrow 110$\n",
    "\n",
    "\n",
    "<br>\n",
    "$e_1 e_2$\n",
    "\n",
    "\n",
    "E.g., if $e_1$ is $f(x)$, we  \n",
    "1. evaluate $e_2$ to a value $v$\n",
    "2. substitute $v$ for $x$ in $f(x)$\n",
    "3. run $f(v)$\n",
    "\n",
    "\n",
    "We assume $\\hbox{Eval}(e_2) = \\hbox{lambda} \\: x \\: . \\: e_3$\n",
    "\n",
    "$[\\hbox{Eval}(e_2)/x]e_3$: all free occurrences of $x$ in $e_3$ are replaced with $\\hbox{Eval}(e_2)$\n",
    "\n",
    "<br>\n",
    "e.g.\n",
    "\n",
    "<br>\n",
    "\n",
    "$f(x) = \\mathtt{lambda} \\: x \\: . \\: x + 1$\n",
    "\n",
    "<br>\n",
    "\n",
    "$W(f(x)(1)) =$  \n",
    "\n",
    "$W(f(x)) + W(1) + W([1 / x](x + 1)) + 1 =$  (by definition of $W(e_1 e_2)$)  \n",
    "\n",
    "$W(f(x)) + W(1) + ( W(1) + W(x+1) + 1 ) + 1 =$  (by definition of $W(e_1 e_2)$)  \n",
    "\n",
    "$1 + 1 + 1 + 1 + 1 =$  \n",
    "\n",
    "$5$\n",
    "\n",
    "<br>\n",
    "$S(f(x)(1)) = 5$\n",
    "\n",
    "<br>\n",
    "\n",
    "**serial composition:**\n",
    "\n",
    "$W(f(x)(1), f(x)(2)) = $\n",
    "\n",
    "$W(f(x)(1)) + W(f(x)(2)) + 1 = $\n",
    "\n",
    "$5 + 5 + 1 = 11$  \n",
    "\n",
    "<br>\n",
    "\n",
    "$S(f(x)(1), f(x)(2)) = $\n",
    "\n",
    "$S(f(x)(1)) + S(f(x)(2)) + 1 = $\n",
    "\n",
    "$5 + 5 + 1 = 11$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**parallel composition:**\n",
    "\n",
    "$W(f(x)(1) || f(x)(2)) = $\n",
    "\n",
    "$W(f(x)(1)) + W(f(x)(2)) + 1 =$\n",
    "\n",
    "$5 + 5 + 1 = 11$  \n",
    "\n",
    "<br>\n",
    "\n",
    "$S(f(x)(1) ||  f(x)(2)) = $\n",
    "\n",
    "$\\max(S(f(x)(1)), S(f(x)(2))) + 1 =$\n",
    "\n",
    "$\\max(5,5) + 1 = 6$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = lambda x: x**2 + 10\n",
    "e2 = lambda y: 5*y\n",
    "\n",
    "e1(\n",
    "    e2(2)  # evaluate e2 to a value v\n",
    "  )        # substitute v for x in e1\n",
    "           # return result of e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## let ... in\n",
    "\n",
    "$W($ `let val`$x=e_1$ `in` $e_2$ `end`$) = 1 + W(e_1) + W([\\hbox{Eval}(e_1)/x]e_2)$\n",
    "\n",
    "Expression $e_2$ is applied using the bindings defined inside **let**.\n",
    "\n",
    "\n",
    "\n",
    "- $[\\hbox{Eval}(e_1)/x]e_2$: all free occurrences of $x$ in $e_2$ are replaced with $\\hbox{Eval}(e_1)$\n",
    "- $W([\\hbox{Eval}(e_1)/x]e_2)$ accounts for this cost.\n",
    "\n",
    "\n",
    "$\\texttt{let}$  \n",
    "$~~~~x = 10*5 ~~~~~ (e_1$)  \n",
    "$\\texttt{in}$   \n",
    "$~~~~x + 100  ~~~~~~~~~~ (e_2)$  \n",
    "$\\texttt{end}$ \n",
    "<br>\n",
    "\n",
    "returns 150\n",
    "\n",
    "<br>\n",
    "\n",
    "$W($ `let val`$x=e_1$ `in` $e_2$ `end`$) = $   \n",
    "\n",
    "$1 + W(e_1) +  W([\\hbox{Eval}(e_1)/x]e_2) = $  \n",
    "\n",
    "$1 + W(e_1) + (W(\\hbox{sub in 50 for x}) + W(x+100) + 1)$ (by function application rule)  \n",
    "\n",
    "$1 + 1 + 1 + 1 + 1 $  \n",
    "\n",
    "$=5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelism\n",
    "\n",
    "how many processors can we use efficiently?\n",
    "\n",
    "\n",
    "**average parallelism**: \n",
    "\n",
    "$$\n",
    "\\overline{P} = \\frac{W}{S}\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "To increase parallelism, we can either:\n",
    "- decrease span\n",
    "- increasing work (but that's not really desireable, since we want the overall cost to be low)\n",
    "\n",
    "<br>\n",
    "\n",
    "**work efficiency**: a parallel algorithm is *work efficient* if it performs asymptotically the same work as the best known sequential algorithm for the problem.\n",
    "\n",
    "So, we want a *work efficient* parallel algorithm with low span.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scheduling\n",
    "\n",
    "Key issue of parallel algorithms is **scheduling**: which processor will run which task when?\n",
    "- typically have more tasks than processors.\n",
    "\n",
    "Recall our parallel sum method:\n",
    "\n",
    "![dag-sum](figures/dag-sum.png)  \n",
    "[source](https://homes.cs.washington.edu/~djg/teachingMaterials/spac/sophomoricParallelismAndConcurrency.pdf)\n",
    "\n",
    "\n",
    "\n",
    "We must decide when to run each part of the sum. There are dependencies that constrain the order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scheduler\n",
    "- For each task generated by a parallel algorithm, assign it to an available processor\n",
    "- Goal: minimize execution time.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "## Greedy Scheduler\n",
    "\n",
    "Whenever there is a processor available and a task ready to execute, assign the task to the processor and start it immediately. \n",
    "\n",
    "Why might this not be optimal?\n",
    "\n",
    "![greedy](figures/greedy.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Greedy schedulers have an important property that is summarized by the greedy scheduling principle.\n",
    "\n",
    "Assuming $P$ processors, then the time $T_P$ to perform computation with work $W$ and span $S$ is bounded by:\n",
    "\n",
    "$T_P < \\frac{W}{P} + S$\n",
    "\n",
    "\n",
    "Because we know:  \n",
    "- $T_P \\ge \\frac{W}{P}$, since that would be the optimal division of work to processors\n",
    "- $T_P \\ge S$, by the definition of span\n",
    "\n",
    "we can conclude that the best we can hope for is:\n",
    "\n",
    "$T_P \\ge \\mathrm{max}(\\frac{W}{P},S)$\n",
    "\n",
    "Therefore the time using a greedy scheduler is bounded by:\n",
    "\n",
    "$ \\mathrm{max}(\\frac{W}{P},S) \\le T_P < \\frac{W}{P} + S$\n",
    "\n",
    "<br>\n",
    "How good is greedy? How close is $(\\frac{W}{P} + S)$ to $\\mathrm{max}(\\frac{W}{P},S)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "actually pretty close.\n",
    "\n",
    "$\\frac{W}{P} + S \\le 2 * \\mathrm{max}(\\frac{W}{P},S)$\n",
    "\n",
    "(why? consider what the worst possible span is...)\n",
    "\n",
    "<br>\n",
    "\n",
    "Greedy scheduler gets better the more parallelism is possible in the algorithm.\n",
    "\n",
    "Recall average parallelism: $\\overline{P} = \\frac{W}{S}$\n",
    "\n",
    "We can rewrite:\n",
    "\n",
    "$T_P < \\frac{W}{P} + S$  \n",
    "$~~~~= \\frac{W}{P} + \\frac{W}{\\overline{P}}$  \n",
    "$~~~~=\\frac{W}{P}(1+\\frac{P}{\\overline{P}})$\n",
    "\n",
    "\n",
    "So, the greater $\\overline{P}$ is than $P$, the closer to optimal we get.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "E.g., recall our parallel sum method, which has\n",
    "\n",
    "$W=O(n)$  \n",
    "$S=O(\\lg n)$\n",
    "\n",
    "<br>\n",
    "$\\overline{P} = \\frac{W}{S} = \\frac{O(n)}{O(\\lg n)}$\n",
    "\n",
    "<br>\n",
    "\n",
    "$ \\mathrm{max}(\\frac{W}{P},S) \\le T_P < \\frac{W}{P} + S$\n",
    "\n",
    "<br>\n",
    "\n",
    "so, if we have 2 processors:\n",
    "\n",
    "$\\mathrm{max}(\\frac{O(n)}{2},O(\\lg n)) \\le T_2 < \\frac{O(n)}{2} + O(\\lg n)$\n",
    "\n",
    "$\\frac{O(n)}{2} \\le T_2 < \\frac{O(n)}{2} + O(\\lg n)$\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "if we have $\\lg n$ processors:\n",
    "\n",
    "\n",
    "$\\mathrm{max}(\\frac{O(n)}{\\lg n},O(\\lg n)) \\le T_{\\lg n} < \\frac{O(n)}{\\lg n} + O(\\lg n)$\n",
    "\n",
    "$\\frac{O(n)}{\\lg n} \\le T_{\\lg n} < \\frac{O(n)}{\\lg n} + O(\\lg n)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "The advantage of the Work-Span model:\n",
    "\n",
    "- We can design parallel algorithms without worrying about scheduling details.\n",
    "\n",
    "- We are ignoring some overhead in the creation of the schedule itself.\n",
    "  - This is acceptable since we are focused on asymptotics (just as in RAM model)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "rise": {
   "autolaunch": true,
   "controls": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "fade"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
