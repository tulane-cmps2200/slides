{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMPS 2200\n",
    "# Introduction to Algorithms\n",
    "\n",
    "## Randomized Algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today's agenda:\n",
    "\n",
    "- Random variables and expectations\n",
    "- Making random choices in algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose you could flip a coin to make a decision in an algorithm, rather than relying on inputs. So:\n",
    "\n",
    "`if (random([0,1] > 0):\n",
    "    print('heads')\n",
    "else:\n",
    "    print('tails')`\n",
    "\n",
    "Why would we ever do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we don't know exactly how to proceed in solving a problem, we can make a random choice and hope we made the right one.\n",
    "\n",
    "Alternately, we can view randomization as helping us avoid always making the wrong choice. \n",
    "\n",
    "Additionally for instances where we might not have a good way to proceed, we can \"guess\" an answer and \"hope\" it's a good choice. \n",
    "\n",
    "What does \"hope\" mean, computationally? A proof that at least most of the time, we are correct/efficient."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Basic Definitions\n",
    "\n",
    "A probability space consists of a **sample space** $\\Omega$ representing the set of possible *outcomes*, and a **probability measure** $\\mathbf{P}: \\Omega \\rightarrow \\mathbb{R}$. The probability measure $\\mathbf{P}$ must satisfy: </p>\n",
    "\n",
    "- **Nonnegativity**: $\\mathbf{P}\\left[{A}\\right] \\in [0,1]$\n",
    "\n",
    "- **Additivity**: For any two disjoint events $A$ and $B$ (i.e., $A \\cap B = \\emptyset$): $\\mathbf{P}\\left[{A \\cup B}\\right] =  \n",
    "  \\mathbf{P}\\left[{A}\\right] + \\mathbf{P}\\left[{B}\\right]$\n",
    "\n",
    "- **Normalization**: $\\mathbf{P}\\left[{\\Omega}\\right] = 1$\n",
    "\n",
    "For example, let $\\Omega$ be the set of all outcomes of a pair of 6-sided dice.\n",
    "\n",
    "How many outcomes are there if the dice sum to 3? To 4?\n",
    "\n",
    "The dice sum to 3 if we roll any of $\\{(1, 2), (2, 1)\\}$, and sum to 4 if we roll any of $\\{(1, 3), (2, 2), (3, 1)\\}.\n",
    "\n",
    "Every outcome is disjoint and has probability $1/36$. So the probability of rolling a 3 is 2/36 = 1/18 and the probability of rolling a 4 is 3/36 = 1/12.\n",
    "\n",
    "If we want to consider multiple, possibly overlapping events. Then, the **union bound** is helpful:\n",
    "\n",
    "$$\\mathbf{P}\\left[{\\bigcup_{0 \\leq i < n} A_i}\\right] \\leq \\sum_{i=0}^{n-1} \\mathbf{P}\\left[{A_i}\\right]$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Probabilities\n",
    "\n",
    "We may want to know the probability of an event $A$ with \"partial knowledge.\"  The **conditional probability** of an event $A$ *given* that $B$ occurs ($\\mathbf{P}\\left[{B}\\right] > 0$) is \n",
    "\n",
    "$$\\mathbf{P}\\left[{A \\mid B}\\right] = \\frac{\\mathbf{P}\\left[{A \\cap B}\\right]}{\\mathbf{P}\\left[{B}\\right]}$$\n",
    "\n",
    "For example, what is the probability of rolling a sum of 6 given that the first die is a 1? 2? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A useful fact that relates conditional probabilities to non-conditional probabilities is the **Law of Total Probability**:\n",
    "\n",
    "Let $\\Omega$ be a sample space and let $A_0, \\ldots, A_{n-1}$ be a set of eventsthat partition  $\\Omega$ such that $\\mathbf{P}\\left[{A_i}\\right] > 0$ for all $0 \\le i < n.$ Then, for any event $B$ we have that: \n",
    "    \n",
    "$\\begin{array}{lll}  \n",
    "\\mathbf{P}\\left[{B}\\right]  & = & \\displaystyle\\sum_{i=0}^{n-1} \\mathbf{P}\\left[{B \\cap A_i}\\right]  \n",
    "\\\\  \n",
    "& = &  \\sum_{i=0}^{n-1} \\mathbf{P}\\left[{A_i}\\right]\\mathbf{P}\\left[{B \\mid A_i}\\right]  \n",
    "\\end{array}$\n",
    "\n",
    "An intuitive way to think about this is that the probability of an event $B$ is just the probability over different possible (disjoint) situations. \n",
    "\n",
    "Another useful concept is **independence**. We say that two events $A$ and $B$ are independent when they are disjoint. So $\\mathbf{P}\\left[{A \\cap B}\\right] = \\mathbf{P}\\left[{A}\\right] \\cdot \\mathbf{P}\\left[{B}\\right].$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Variables and Expectations\n",
    "\n",
    "A **random variable** $X$ is a real-valued function on the outcomes of an experiment, i.e., $X : \\Omega\\to \\mathbb{R}$, i.e., it assigns a real number to each outcome. We will consider discrete random variables.\n",
    "\n",
    "Even more simply, we will most often use **indicator random variables**, which map outcomes to 0 or 1. \n",
    "\n",
    "Note: The term \"random variable\" is somewhat odd. Really it's just a function, but we use this terminology since it's useful to look at functions of outcomes (which have probabilities under a given probability measure). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The **expectation** of a random variable $X$ defined for a probability space $(\\Omega, \\mathbf{P})$ is denoted:\n",
    "\n",
    "$$\\mathbf{E}_{\\Omega,\\mathbf{P}}[X] = \\sum_{y \\in \\Omega} X(y) \\cdot  \n",
    "\\mathbf{P}\\left[\\{y\\}\\right].$$\n",
    "\n",
    "We usually write this more conveniently as:\n",
    "\n",
    "$$ \\mathbf{E}\\left[{X}\\right] = \\sum_{x} x \\cdot \\mathbf{P}\\left[X = x\\right]. $$\n",
    "\n",
    "Let $X$ be the value of a pair of dice. $X$ can take on values between 2 and 12, where each has a certain probability based on the possible ways the dice can sum to that value.  What is the expected value of the value of a pair of unbiased dice? It is:\n",
    "\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    "\\mathbf{E}\\left[{X}\\right] &=& \\sum_{x=2}^{12} x \\cdot \\mathbf{P}\\left[X = x\\right] \\\\\n",
    "&=& 2\\cdot\\frac{1}{36} + 3\\cdot\\frac{2}{36} + 4\\cdot\\frac{4}{36} + \\cdots + 11\\cdot\\frac{2}{36} + 12\\cdot\\frac{1}{36}\n",
    "\\end{eqnarray*}$\n",
    "\n",
    "<p><br><br>\n",
    "Intuitively, the expectation is really just a weighted average of the values of the random variable.\n",
    "    \n",
    "Let's look at coin flips where we have equal probability of heads/tails. Let $X$ be the number of flips until we get heads. What is $E[X]$? Observe that:\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    "E[X] &=& \\frac{1}{2}\\cdot 1 + \\frac{1}{2} (1 + E[X]) \\\\\n",
    "\\end{eqnarray*}$\n",
    "\n",
    "Solving for $E[X]$, we get that $E[X] = 2$. More generally, the expected number of trials to get an outcome of probability $p$ is $1/p$. (We'll see this later.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make repeated use of some basic facts about the expectations of random variables.\n",
    "\n",
    "First, we can easily treat the expected value of functions of random variables:\n",
    "    \n",
    "$$ \\mathbf{E}\\left[f(X)\\right] = \\sum_{x} f(x) \\cdot \\mathbf{P}\\left[X = x\\right]. $$\n",
    "\n",
    "We also have **linearity of expectations** for random variables:\n",
    "\n",
    "$$ \\mathbf{E}\\left[X + Y\\right] = \\mathbf{E}\\left[X\\right] + E\\left[ Y\\right]. $$\n",
    "\n",
    "This identity will help us simply the calcuation of the *expected* work and span of an algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How does all this relate to algorithms?\n",
    "\n",
    "The sample space we must consider for an algorithm is the set of decisions made by the algorithm. We typically use random variables that map outcomes to a way to measure work/span.\n",
    "\n",
    "However it is usually difficult to reason directly about the overall outcome (e.g. correctness or work/span), so we try to identify when choices are independent or conditional upon one another.\n",
    "\n",
    "Ultimately if we choose to make random choices in our algorithm, we must relax our notion of correctness and our definitions of work/span.\n",
    "\n",
    "For correctness, some executions may produce the wrong output while others are correct. We usually seek to have a very high *probability of correctness*. \n",
    "\n",
    "For work/span, some executions may take longer than others. We seek to provide asymptotic bounds on the *expected* work or span of a randomized algorithm. Intuitively, this is the weighted average of the running times over all possible sets of random choices. \n",
    "\n",
    "When using randomization we usually have one of two types of algorithms.\n",
    "\n",
    "A **Monte Carlo** randomized algorithm has a **deterministic** worst-case runtime but a randomized output that is correct with some probability.\n",
    "\n",
    "A **Las Vegas** randomized algorithm always produces a correct solution, but has an **expected** runtime.  \n",
    "\n",
    "We will focus on Las Vegas algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Randomly splitting a list\n",
    "\n",
    "Suppose we are given a list $L$ of length $n$. We choose a random index $i$ of the list and return $L[i:]$ as output. \n",
    "\n",
    "What is the expected size of $L[i:]? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Let $X$ be a random variable that is the size of the output list. By the definition of expectation we have:\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    "\\mathbf{E}[X] &=& \\sum_{x=1}^{n} x \\cdot \\mathbf{P}[X = x] \\\\\n",
    "&=& \\sum_{x=1}^{n} x \\cdot \\frac{1}{n} \\\\\n",
    "&=& \\frac{1}{n}\\cdot\\sum_{x=1}^{n} x \\\\\n",
    "&=& \\frac{1}{n}\\cdot\\frac{n(n+1)}{2}\\\\\n",
    "&=& \\frac{n+1}{2} \\\\\n",
    "\\end{eqnarray*}$\n",
    "\n",
    "This might follow your intuition that, since all indices are equally likely, the chosen index averages out to roughly half of the list size. \n",
    "\n",
    "A related question is, what is the probability of getting a list with more than half of the elements? That is, what is $\\mathbf{P}\\left[X \\geq n/2\\right]$?\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    "\\mathbf{P}\\left[X \\geq n/2\\right] &=& \\sum_{x=n/2}^{n} \\mathbf{P}[X = x] \\\\\n",
    "&=& \\sum_{x=n/2}^{n} \\frac{1}{n} \\\\\n",
    "&=& \\frac{1}{n}\\cdot\\sum_{x=n/2}^{n} 1 \\\\\n",
    "&=& \\frac{n/2}{n} \\\\\n",
    "&=& \\frac{1}{2} \\\\\n",
    "\\end{eqnarray*}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Randomly filtering elements\n",
    "\n",
    "Suppose we are given a list of length $L$ of length $n$. \n",
    "\n",
    "For each element we flip an unbiased coin $x_i$. Return a list $R$ with $L[i]$ such that $x_i$ is heads.\n",
    "\n",
    "What is the expected size of $R$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let $X_i$ be an indicator random variable that is 1 if element $i$ is chosen, and 0 otherwise. Let $X$ be the size of $R$. We can see that $X = \\sum_{i=0}^{n-1} X_i$ by definition. So by linearity of expectation we can compute:\n",
    "\n",
    "$$\\mathbf{E}[X] = \\sum_{i=0}^{n=1} \\mathbf{E}[X_i].$$\n",
    "\n",
    "Now notice that by the definition of expectation \n",
    "\n",
    "$$E[X_i] = 0\\cdot \\mathbf{P}[X_i = 0] + 1\\cdot\\mathbf{P}[X_i = 1] = \\mathbf{P}[X_i = 1].$$\n",
    "\n",
    "Since we flip a coin for each element independently, $\\mathbf{P}[X_i = 1] = 1/2.$ Thus, $\\mathbf{E}[X_i] = 1/2$ for all $i$. So we have that\n",
    "\n",
    "$$\\mathbf{E}[X] = \\sum_{i=0}^{n=1} \\frac{1}{2} = \\frac{n}{2}.$$\n",
    "\n",
    "\n",
    "So the expected size of $R$ is $n/2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These simplistic algorithms illustrate the kind of analysis we will be doing to analyze the expected work and span of algorithms for manipulating lists. \n",
    "\n",
    "We will look at algorithms for selection and sorting. For both problems we will analyze recursive algorithms that use randomization to select the input for the recursive calls. \n",
    "\n",
    "This creates a complicated situation in which each successive call depends on the previous one, and thereby requires some clever accounting to derive the expected work and span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "rise": {
   "autolaunch": true,
   "controls": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "fade"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
